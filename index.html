<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="nl">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title>AB Statistics Presentation</title>

		<script type="text/javascript" src="jquery/jquery-3.2.1.js"></script>
		<script type="text/javascript" src="d3/d3.js"></script>
		<script type="text/javascript" src="vue/vue.js"></script>
		<script src="bootstrap/js/bootstrap.min.js"></script>
		
		<link href="bootstrap/css/bootstrap.min.css" rel="stylesheet">
		<link rel="stylesheet" href="reveal/css/reveal.css">
		<link rel="stylesheet" href="reveal/css/theme/white.css">
		<style>
			.text-very-muted {
				color: #BBB;
			}
			.reveal h1 {
				line-height: 0.9em;
				margin-bottom: 0.75em;
			}
			
			h1 span.title-divider {
				overflow: hidden;
				text-align: center;
				display: block;
				font: 90px "Times New Roman";
				font-style: oblique;
				text-transform: lowercase;
				margin: -0.2em auto 0.1em;
			}
			h1 span.title-divider:before,
			h1 span.title-divider:after {
				background-color: #000;
				content: "";
				display: inline-block;
				height: 2px;
				border-radius: 100%;
				position: relative;
				vertical-align: middle;
				width: 50%;
			}
			h1 span.title-divider:before {
				right: 0.5em;
				margin-left: -50%;
			}
			h1 span.title-divider:after {
				left: 0.5em;
				margin-right: -50%;
			}
			.reveal table td.align-center {
				text-align: center;
			}
			.reveal table th.align-center {
				text-align: center;
			}
			.reveal table td.big-font {
				font-size: 90px;
			}
			.reveal table.align-center-except-first-column th:nth-child(1n+2),
			.reveal table.align-center-except-first-column td:nth-child(1n+2) {
				text-align: center;
			}
		</style>
	</head>
	<body>
		<script type="text/javascript">
			var SPEED = 100;
						
			Vue.component('simulation', {
				template: `
					<div class="container">
						<p><small class="text-muted"><var>n</var> = <var>{{n}}</var>, <var>base conversion rate</var> = <var>{{cr}}</var>, <var>effect of treatment</var> = <var>{{effect}}</var></small></p>
						<div class="stretch chart-container"></div>
						<div class="text-center">
							<button type="button" class="btn btn-default" v-on:click="step">Step</button>
							<button type="button" class="btn btn-default" v-on:click="toggle_repeat">{{ this.repeating ? 'Pause' : 'Repeat'}}</button>
						</div>
						<div class="row">
							<table class="table table-striped">
								<thead>
									<tr>
										<th v-if="display_true_effect" class="align-center">simulated effect</th>
										<th v-if="display_observed_effect" class="align-center">average observed effect</th>
										<th v-if="display_type_i" class="align-center">type-I error rate</th>
										<th v-if="display_type_ii" class="align-center">type-II error rate</th>
										<th v-if="display_power" class="align-center">observed power</th>
									</tr>
								</thead>
								<tbody>
									<tr>
										<td v-if="display_true_effect" class="align-center big-font">{{this.effect}}</td>
										<td v-if="display_observed_effect" class="align-center big-font">{{averages.total ? averages.total.toFixed(5) : "-"}}</td>
										<td v-if="display_type_i" class="align-center big-font">{{type_i_error.toLocaleString('us', {style: 'percent'})}}</td>
										<td v-if="display_type_ii" class="align-center big-font">{{type_ii_error.toLocaleString('us', {style: 'percent'})}}</td>
										<td v-if="display_power" class="align-center big-font">{{power.toLocaleString('us', {style: 'percent'})}}</td>
									</tr>
								</tbody>
							</table>
						</div>
					</div>
				`,
				props: {
					effect: 					{ type: Number, default: 0 },
					n:  						{ type: Number, default: 1000 },
					display_true_effect: 		{ type: Boolean, default: false },
					display_observed_effect:	{ type: Boolean, default: false },
					display_type_i:				{ type: Boolean, default: false },
					display_type_ii:			{ type: Boolean, default: false },
					display_power: 				{ type: Boolean, default: false },
				},
				data: function () {
					return {
						w: 1140,
						h: 500,
						margin: {top: 10, right: 20, bottom: 20, left: 20},
						bins: 200,
						cr: 0.1,
						bounds: [-0.2,0.2],
						results: { significant: [], insignificant: [], significant_opposite: [] },
						g: '',
						repeating: false,
						my_slide: null,
					}
				},
				computed: {
					width: function() { return +this.w - this.margin.left - this.margin.right },
					height: function() { return +this.h - this.margin.top - this.margin.bottom},
					averages: function() {
						var a = {}, total_sum = 0;
						for (var k in this.results) {
							if (this.results[k].length == 0) { 
								a[k] = NaN;
							} else {
								var sum = this.results[k].reduce(function(a, b) { return a + b; });
								a[k] = sum / this.results[k].length;
								total_sum += sum;
							}
						}
						a.total = total_sum / this.trials;
						return a;
					},
					average_abs_effect: function() {
						return ((this.averages.significant * this.results.significant.length) + 
								(Math.abs(this.averages.significant_opposite||0) * this.results.significant_opposite.length))
								/ (this.results.significant.length + this.results.significant_opposite.length);
					},
					type_i_error: function() {
						if (this.effect != 0) return "-"; // if null is false, type-I error is undefined.
						if (this.trials == 0) return "-";
						if (this.results.significant.length + this.results.significant_opposite.length == 0) return 0;
						return (this.results.significant.length + this.results.significant_opposite.length) / this.trials;
					},
					type_ii_error: function() {
						if (this.effect == 0) return "-"; // if null is true, type-II error is undefined.
						if (this.trials == 0) return "-";
						return 1 - this.power;
					},
					type_m_error: function() {
						return this.average_abs_effect / this.effect;
					},
					type_s_error: function() {
						return this.results.significant_opposite.length / (this.results.significant.length + this.results.significant_opposite.length);
					},
					trials: function() {
						return this.results.significant.length + this.results.significant_opposite.length + this.results.insignificant.length;
					},
					power: function() {
						if (this.effect == 0) return "-"; // if null is true, power is undefined.
						if (this.trials == 0) return "-";
						return (this.results.significant.length + this.results.significant_opposite.length) / this.trials;
					}
				},
				mounted: function() {	
					var svg = d3.select(this.$el).select('.chart-container').append("svg")
						.attr("width", '100%')
						.attr("height", '100%')
						.attr('viewBox','0 0 '+this.w+' '+this.h)
						.attr('preserveAspectRatio','xMinYMin');

					this.g = d3.select(this.$el).select("svg").append("g").attr("transform", "translate(" + this.margin.left + "," + this.margin.top + ")");
					this.update(this.results);
					d3.interval(this.repeat, SPEED);
				},
				methods: {
					update: function(data) {
						var x = d3.scaleLinear().domain(this.bounds).rangeRound([0, this.width]);
						var histogram = d3.histogram().domain(x.domain()).thresholds(x.ticks(this.bins));
						var b1 = histogram(this.results.significant);
						var b2 = histogram(this.results.significant_opposite);
						var b3 = histogram(this.results.insignificant);
						var b = d3.stack().keys(d3.range(3))(d3.transpose([b1.map(function(d) {return d.length}),b2.map(function(d) {return d.length}),b3.map(function(d) {return d.length})]));
						var y = d3.scaleLinear().domain([0, d3.max(b[2], function(d) { return d[1]; })]).range([this.height, 0]);
						var color = d3.scaleOrdinal().domain(d3.range(3)).range(d3.schemeCategory20);
						var colorsort = [0,2,1];

						var series = this.g.selectAll(".series").data(b);						
						series.enter().append("g")
								.attr("class", "series")
								.attr("fill", function(d, i) { return color(colorsort[i]); })
							.merge(series);

						var rect = series.selectAll("rect").data(function(d) { return d; });
						rect.enter().append("rect")
								.attr("x", 1)
								.attr("width", x(b1[0].x1) - x(b1[0].x0))
								.attr("transform", function(d, i) { return "translate(" + x(b1[i].x0) + "," + y(d[0]) + ")"; })
								.attr("height", 0)
							.merge(rect)
								.transition().duration(SPEED)
									.attr("transform", function(d, i) { return "translate(" + x(b1[i].x0) + "," + y(d[1]) + ")"; })
									.attr("height", function(d) { return y(0) - y(d[1]-d[0]); });
						
						this.g.selectAll(".axis").remove();
						this.g.append("g")
							.attr("class", "axis axis--x")
							.attr("transform", "translate(0," + this.height + ")")
							.call(d3.axisBottom(x));
					},
					step: function() {
						var n = this.trials;
						if (n >= 1000000) return;
						for (var j = 0; j < Math.min(1000,10**(""+(n)).length/10); ++j) {
							base_n = this.rbinom(this.n, 0.5);
							var_n = this.n - base_n;
							
							base_c = this.rbinom(base_n, this.cr);
							var_c = this.rbinom(var_n, (this.cr + this.effect));
							
							effect = (var_c/var_n) - (base_c/base_n);
							gval = calculate_g_test([[base_n - base_c, base_c], [var_n - var_c, var_c]]);

							if (gval >= 3.841459) {
								if (effect > 0) {
									this.results.significant.push(effect);
								} else {
									this.results.significant_opposite.push(effect);
								}
							} else {
								this.results.insignificant.push(effect);
							}
						}
					},
					toggle_repeat: function() {
						this.repeating = !this.repeating;
						this.my_slide = Reveal.getIndices().h;
					},
					repeat: function() {
						if (this.repeating && Reveal.getIndices().h == this.my_slide) { this.step(); }
					},
					rbinom: function(n, p) {
						var b = 0;
						for (var i = 0; i < n; ++i) { if (Math.random() < p) ++b; };
						return b;
					},
				},
				watch: {
					trials: function(val) { this.update(val) }
				}
			});
			
			// This takes an array of arrays of any size, and calculates
			// the raw g-test value.  It assumes a square matrix of arguments.
			function calculate_g_test (data) {
				var rows = data.length;
				var columns = data[0].length;

				// Initialize our subtotals
				var row_totals = [];
				for (var i = 0; i < rows; i++) {
					row_totals[i] = 0;
				}

				var column_totals = [];
				for (var j = 0; j < columns; j++) {
					column_totals[j] = 0;
				}

				var total = 0;

				// First we calculate the totals for the row and the column
				for (var i = 0; i < rows; i++) {
					for (var j = 0; j < columns; j++) {
						var entry = data[i][j] - 0;  // - 0 ensures numeric
						row_totals[i]    += entry;
						column_totals[j] += entry;
						total            += entry;
					}
				}

				// Now we calculate the g-test contribution from each entry.
				var g_test = 0;;
				for (var i = 0; i < rows; i++) {
					for (var j = 0; j < columns; j++) {
						var expected = row_totals[i] * column_totals[j] / total;
						var seen     = data[i][j];

						g_test      += 2 * seen * Math.log( seen / expected );
					}
				}

				return g_test;
			};
		</script>

		<div class="reveal">
			<div class="slides">
				<section>
					<h1>Design <span class="title-divider">of</span> experiments</h1>
					<p>
						Statistical foundations for people who do not like math
						<br />
						<span class="text-very-muted">(and let’s be honest, very few people <em>really</em> like math)</span>
					</p>
					<br />
					<p>
						<small>
							Lukas Vermeer <span class="text-very-muted">is</span> Senior Product Owner <span class="text-very-muted">for</span> Experimentation <span class="text-very-muted">at</span> Booking.com
						</small>
					</p>
					<p>
						<small>							
							<a href="http://twitter.com/lukasvermeer" target="_blank">@lukasvermeer</a> &mdash; <a href="http://lukasvermeer.github.io/ab-stats" target="_blank">lukasvermeer.github.io/ab-stats</a>
						</small>
					</p>
				</section>
				
				<section data-markdown>
					## Controlled Experiments for Hypothesis Testing

					- We want gather evidence for a causal link between a change and behaviour
						- “By switching to B, we will cause more people to click ads or buy our product!”
					- Correlation is not sufficient for supporting decision making
						- Direction of effect is as important as showing there is a relation at all
						- Banning umbrellas will not stop the rain; it will just make everyone more wet
				</section>
				
				<section data-markdown>
					## Controlled Experiments for Hypothesis Testing
					
					- We will want to refute the hypothesis that there is no effect
						- We will consider rejection of the “null hypothesis” as evidence for the “alternative hypothesis”
					- We will encounter two main types of uncertainty
						- Is there any causal effect?
						- What is the size of the causal effect?
				</section>
				
				<section>
					<h3>Rubin causal model <small>(what we want to know)</small></h3>
					
					<table class="table table-striped align-center-except-first-column">
						<thead>
							<tr>
								<th></th>
								<th>Under A</th>
								<th>Treatment Effect</th>
								<th>Under B</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Alice</td>
								<td>0.4</td>
								<td>0.1</td>
								<td>0.5</td>
							</tr>
							<tr>
								<td>Bob</td>
								<td>0.3</td>
								<td>0.1</td>
								<td>0.4</td>
							</tr>
							<tr>
								<td>Charlie</td>
								<td>0.5</td>
								<td>0.1</td>
								<td>0.6</td>
							</tr>
							<tr>
								<td>Dirk</td>
								<td>0.2</td>
								<td>0.1</td>
								<td>0.3</td>
							</tr>
							<tr>
								<td>(Everyone)</td>
								<td>...</td>
								<td>...</td>
								<td>...</td>
							</tr>
							<tr class="info">
								<td>Average</td>
								<td>0.35</td>
								<td><b>0.1</b></td>
								<td>0.45</td>
							</tr>

						</tbody>
					</table>
					
					<p><small>[1] Rubin, Donald B. 1974. “Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.” Journal of Educational Psychology 66 (5): 688–701.</small></p>
				</section>

				<section>
					<h3>Rubin causal model <small>(what we can measure)</small></h3>
					
					<table class="table table-striped align-center-except-first-column">
						<thead>
							<tr>
								<th></th>
								<th>Under A</th>
								<th>Treatment Effect</th>
								<th>Under B</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Alice</td>
								<td>Yes</td>
								<td>?</td>
								<td>?</td>
							</tr>
							<tr>
								<td>Bob</td>
								<td>?</td>
								<td>?</td>
								<td>No</td>
							</tr>
							<tr>
								<td>Charlie</td>
								<td>No</td>
								<td>?</td>
								<td>?</td>
							</tr>
							<tr>
								<td>Dirk</td>
								<td>?</td>
								<td>?</td>
								<td>Yes</td>
							</tr>
							<tr>
								<td>(Sample)</td>
								<td>...</td>
								<td>...</td>
								<td>...</td>
							</tr>
							<tr class="info">
								<td>Average</td>
								<td>?</td>
								<td><b>?</b></td>
								<td>?</td>
							</tr>

						</tbody>
					</table>

					<p><small>[1] Rubin, Donald B. 1974. “Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.” Journal of Educational Psychology 66 (5): 688–701.</small></p>
				</section>

				<section data-markdown>
					## Gathering evidence for causality
					
					- The “fundamental problem of causal inference” limits what we can measure
						- We cannot sample the entire population
						- We cannot expose units to both treatments exclusively
						- We cannot directly observe underlying probabilities
					- Randomized controlled trials can help us gather evidence for causality
						- Random assignment does not depend on externalities and controls for other factors
				</section>
				
				<section data-markdown>
					 ## Gathering evidence for causality
					 
					- Controlling for other things, only a few possible explanations remain
						- **Causation** resulted in people behaving differently after treatment was applied 
						- **Pure chance** resulted in a difference in the groups that was unrelated to the treatment
						- **Measurement error** resulted in a difference unrelated to the experiment
					- Controlled experiments are not the panacea for everything. ​
						- Issues discussed in the journal survey paper ([http://bit.ly/expSurvey](http://bit.ly/expSurvey))​
				</section>

				<section data-markdown>
					## Randomisation and expectation
					
					- In expectation, the average of a random sample will approximate true mean of the population
					- In expectation, the fraction of wins will approximate underlying probability
						- We do not need to observe the probabilities directly if we have the outcomes for individuals
					- In expectation, the difference between averages will give us the ATE
						- We do not need to measure the treatment effects of each individual participant

					**If we show A and B to random samples of the population, the difference between the fraction of wins in both groups will approximate the average treatment effect.**
				</section>

				<section>
					<h3>Rubin causal model <small>(what randomisation gives us)</small></h3>
					
					<table class="table table-striped align-center-except-first-column">
						<thead>
							<tr>
								<th></th>
								<th>Under A</th>
								<th>Treatment Effect</th>
								<th>Under B</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Alice</td>
								<td>Yes</td>
								<td>?</td>
								<td>?</td>
							</tr>
							<tr>
								<td>Bob</td>
								<td>?</td>
								<td>?</td>
								<td>No</td>
							</tr>
							<tr>
								<td>Charlie</td>
								<td>No</td>
								<td>?</td>
								<td>?</td>
							</tr>
							<tr>
								<td>Dirk</td>
								<td>?</td>
								<td>?</td>
								<td>Yes</td>
							</tr>
							<tr>
								<td>(Sample)</td>
								<td>...</td>
								<td>...</td>
								<td>...</td>
							</tr>
							<tr class="info">
								<td>Average</td>
								<td>0.5</td>
								<td><b>0.0</b></td>
								<td>0.5</td>
							</tr>

						</tbody>
					</table>

					<p><small>[1] Rubin, Donald B. 1974. “Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.” Journal of Educational Psychology 66 (5): 688–701.</small></p>
				</section>
				
				<section id="app-expectation">
					<simulation v-bind:effect="0.1" display_true_effect display_observed_effect></simulation>
				</section>

				<section data-markdown>
					## Randomization introduces quantifiable uncertainty
					
					- Every randomisation will likely give us a slightly different result
						- Every time the experiment is repeated with new randomisation, the averages will be different
						- We can quantify an expected range of results using a confidence interval
					- Sometimes we will get “unlucky” in our randomisation
						- We might randomly put all the men in one group and all the women in the other 
						- We can estimate the likelihood of getting a particular result by chance using a test statistic
				</section>

				<section data-markdown>
					## Randomization introduces quantifiable uncertainty
					
					- Other potential, but unquantifiable, sources of uncertainty also exist
						- The population may change
						- The treatment may change
						- The effect may change
					- Stability of these other factors is (often implicitly) assumed
				</section>

				<section data-markdown>
					## Confidence intervals
					
					- Every randomisation will assign treatment differently
						- If we were to repeat the same experiment, assignment would change
						- As a result, we would expect group averages to vary as well
					- We can quantify the expected range of variation using a confidence interval
						- We can expect results to be between X and Y 95% of the times we repeat the experiment
				</section>

				<section data-markdown>
					## Confidence intervals
					
					- This will (sadly) not tell us much about the true value of the parameter
						- Counter intuitively, this does not prove the true value lies between X and Y with probability
						- We can also not assume the true value lies “somewhere in the middle”
						- Only that, in expectation, repeated sampling will result in values in that range
				</section>

				<section data-markdown>
					## Test statistics (p-values) 

					- Even with a fair die we might roll a six twice in a row
						- The odds of rolling two sixes are one in six times one in six (⅙ * ⅙ * 100 ~= 2.78%)
					- Even after three sixes, there is a chance that the die is fair and we got lucky
						- The odds of rolling three sixes are pretty slim (⅙ * ⅙ * ⅙ * 100 ~= 0.46%)
					
					**The p-value is the probability of getting a result or more extreme by chance assuming there is no effect at all**
				</section>

				<section data-markdown>
					## Test statistics (p-values)
					
					- We might argue that small odds support accepting an alternative explanation
						- For instance that the die is loaded, of that I can influence the result through telepathy
					- Sometimes we will get “unlucky” in our randomisation
						- We will have to decide at which point we will reject the idea that our result could be chance
						- At this point, we will accept the alternative hypothesis and argue there is a causal effect
				</section>

				<section>
					<h2>Misinterpreting p-values</h2>

					<ul>					
						<li>p-values are often misinterpreted</li>
						<ul>
							<li>p-value gives us Prob(X >= x | H0), whereas what we want is Prob(H0 | X = x)</li>
						</ul>
						<li>Here are some incorrect statements from Steve Goodman’s A Dirty Dozen[2]</li>
						<ul>
							<li>If p = .05, the null hypothesis has only a 5% chance of being true</li>
							<li>A non-significant difference (e.g. p > .05) means there is no difference between groups</li>
							<li>p = .05 means that we have observed data that would occur only 5% of the time under the null</li>
							<li>p = .05 means that if you reject the null, the probability of a type I error (false positive) is 5%</li>
						</ul>
					</ul>
					<p><small>[2] Goodman, Steve 2008. “A dirty dozen: twelve P-value misconceptions.” Seminars in Hematology, 45 (2008), pp. 135-140.</small></p>
				</section>

				<section data-markdown>
					## Misinterpreting p-values
					
					- In many sciences, the standard threshold to reject the null is p < 0.05
						- Note that rolling two sixes already meets this threshold (since ⅙ * ⅙ < 0.05)
					- In the absence of an effect, we might still (falsely) reject the null
						- This is called a “type-I” error
						- When the boy cried wolf, there was none
				</section>

				<section id="app-type-i">
					<simulation v-bind:effect="0.0" display_true_effect display_type_i></simulation>
				</section>

				<section data-markdown>
					## Type-II errors and statistical power
					
					- In the presence of an effect, we might still (falsely) fail to reject the null
						- This is called a “type-II” error
						- When the wolf showed up, the boy failed to cry
					- The result might simply not be that unlikely when assuming the null is true
					
					**Statistical power is the probability that the test correctly rejects the null hypothesis when the alternative hypothesis is true.**
				</section>

				<section data-markdown>
					## Type-II errors and statistical power
					
					- Two main things that affect statistical power
						- Sample size (more is better)
						- Effect size (more is better)
					- Effect size is unknown but assumed fixed
					- Sample size may be increased is low power is expected
				</section>

				<section id="app-type-ii">
					<simulation v-bind:effect="0.05" display_type_ii display_power></simulation>
				</section>

				<section id="app-type-ii-2">
					<simulation v-bind:effect="0.05" v-bind:n="2000" display_type_ii display_power></simulation>
				</section>

				<section data-markdown>
					## Multiple comparison and other protocol violations
					
					- The methods described assume strict adherence to experiment protocol
						- A versus B
						- Test a single hypothesis once
						- Test for significance only once
					- Deviations from protocol can increase error rate or introduce biased estimates
						- Multiple testing increases type-I error rate
						- Variant selection bias inflates estimate of average treatment effect
				</section>

				<section data-markdown>
					## Multiple comparison and other protocol violations

					- Correcting for these deviations from standard protocol is possible
						- See for example([www.exp-platform.com/Documents/p609-deng.pdf](www.exp-platform.com/Documents/p609-deng.pdf))
					- More flexible protocols may be desirable
						- Early stopping rules to mitigate damage from bad experiments
						- Early shipping to minimize opportunity cost
				</section>

				<section data-markdown>
					## Questions?
				</section>
			</div>
		</div>
		
		<script src="reveal/lib/js/head.min.js"></script>		
		<script src="reveal/js/reveal.js"></script>
		<script type="text/javascript">
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
				width: 1140,
				height: 960,
				margin: 0.05,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'reveal/lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'reveal/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'reveal/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'reveal/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'reveal/plugin/zoom-js/zoom.js', async: true },
					{ src: 'reveal/plugin/notes/notes.js', async: true }
				]
			});

			new Vue({ el: '#app-expectation' });
			new Vue({ el: '#app-type-i' });
			new Vue({ el: '#app-type-ii' });
			new Vue({ el: '#app-type-ii-2' });
		</script>
	</body>
</html>